%--------------------------------------------------------------------------------------%--------------------------------------------------------------------------------------
%
%  Global settings, dont change it! (excapt additional \usepackage commands)
%  Always use PDFLatex!
%
%--------------------------------------------------------------------------------------%--------------------------------------------------------------------------------------
\documentclass[a4paper, 12pt, oneside, BCOR1cm,toc=chapterentrywithdots]{scrbook}

\usepackage{graphicx}           % use for pdfLatex
\usepackage{makeidx} % f\"{u}r Benutzung des Befehls \printindex
\usepackage[colorlinks=false]{hyperref}
\usepackage{tocbibind}
\usepackage{blindtext}
\usepackage{subfigure} 
\usepackage{acronym}
\usepackage{amsmath}

\hypersetup{%
bookmarksnumbered=true, hyperindex=true,
%
%Im Acrobat Reader Subtitel 1. Ebene anzeigen
bookmarksopen=true, bookmarksopenlevel=1,
%
pdfborder=0 0 0 % Keine Box um die Links!
}

% --------------------------------------------------------------
% Force Tables and List to be added in Table of Content
% --------------------------------------------------------------

\renewcommand*{\tableofcontents}{%
  	\begingroup
  	\tocsection
  	\tocfile{\contentsname}{toc}
  	\endgroup
}
\renewcommand*{\listoffigures}{%
  	\begingroup
  	\tocsection
  	\tocfile{\listfigurename}{lof}
  	\endgroup
}
\renewcommand{\listoftables}{
	\begingroup
	\tocsection
	\tocfile{\listtablename}{lot}
	\endgroup
}
\begin{document}

%--------------------------------------------------------------------------------------%--------------------------------------------------------------------------------------
%
%  Here starts the userspace !
%
%--------------------------------------------------------------------------------------%--------------------------------------------------------------------------------------

%--------titlepage
\begin{titlepage}

{
    \begin{center}
        \raisebox{-1ex}{\includegraphics[scale=1.5]{TU_Chemnitz_positiv_gruen.pdf}}\\
    \end{center}
    \vspace{0.5cm}
}

\begin{center}

\LARGE{\textbf{Driver head orientation detection using Transfer Learning}}\\
\vspace{1cm}


\Large{\textbf{Research Project}}\\ 
\vspace{1cm}
Submitted in Fulfilment of the\\
Requirements for the Academic Degree\\
M.Sc.\\
\vspace{0.5cm}
Dept. of Computer Science\\
Chair of Computer Graphics and Visualization
\end{center}
\vspace{2cm}
Submitted by: Adarsh Mallandur\\
Student ID: 457084\\
Date: 19.06.2018\\
\vspace{0.3cm}\\
Supervising tutor: Stephen Helmert \\

\end{titlepage}

%---------------------------------------------------------
% Abstract
%---------------------------------------------------------

\addchap*{Abstract}
Estimating the head pose of the driver is a crucial as well as one of the difficult problems in the task of driver attention monitoring systems, given the problems of occlusions, illumination changes and the different poses of the driver. It is useful especially in highly autonomous vehicles where the handoff time to human driver needs to be determined. Traditionally head pose is estimated by detecting facial landmarks and solving the problem of 2D to 3D correspondence. This is a fragile method since it depends entirely on the estimation of landmarks which is difficult especially when there are occlusions and variations in illuminations. In this research project, a more robust way of estimating the head pose is done by training a convolutional neural network through the method of transfer learning. In our case, a network pre-trained on ImageNet dataset is used as feature extractor and further trained on DrivFace, a dataset containing images sequences of subjects while driving in real scenarios. This network classifies the RGB images into three classes: looking left, looking front and looking right. Results show that the method of transfer learning overcomes a DeepaGaze, a head pose estimation framework trained on in-the-wild datasets.
\\\\
\textbf{Keywords: Convolutional neural networks, transfer learning, head pose estimation, deep learning}

%---------------------------------------------------------
% Table of Contents, List of figures, List of Tables
%---------------------------------------------------------

\tableofcontents
\listoffigures
\listoftables

%---------------------------------------------------------
% List of Abbreviations
%---------------------------------------------------------
\twocolumn
\addchap{List of Abbreviations}
\begin{acronym}[Bash]
 \acro{ADAS}{Advanced Driver Assistance Systems}
 \acro{CNN}{Convolutional Neural Networks}
 \acro{Bash}{Bourne-again shell}
 \acro{JDK}{Java Development Kit}
 \acro{VM}{Virtuelle Maschine}
 \acro{I2C}[I²C]{Inter-Integrated Circuit}
 \acro{KDE}{K Desktop Environment}
 \acro{SQL}{Structured Query Language}
 \acro{Bash}{Bourne-again shell}
 \acro{JDK}{Java Development Kit}
 \acro{VM}{Virtuelle Maschine}
 \acro{I2C}[I²C]{Inter-Integrated Circuit}
 \acro{KDE}{K Desktop Environment}
 \acro{SQL}{Structured Query Language}
 \acro{Bash}{Bourne-again shell}
 \acro{JDK}{Java Development Kit}
 \acro{VM}{Virtuelle Maschine}
 \acro{I2C}[I²C]{Inter-Integrated Circuit}
 \acro{KDE}{K Desktop Environment}
 \acro{SQL}{Structured Query Language}
 \acro{Bash}{Bourne-again shell}
 \acro{JDK}{Java Development Kit}
 \acro{VM}{Virtuelle Maschine}
 \acro{I2C}[I²C]{Inter-Integrated Circuit}
 \acro{KDE}{K Desktop Environment}
 \acro{SQL}{Structured Query Language}
 \acro{Bash}{Bourne-again shell}
 \acro{JDK}{Java Development Kit}
 \acro{VM}{Virtuelle Maschine}
 \acro{I2C}[I²C]{Inter-Integrated Circuit}
 \acro{KDE}{K Desktop Environment}
 \acro{SQL}{Structured Query Language}
 \acro{Bash}{Bourne-again shell}
 \acro{JDK}{Java Development Kit}
 \acro{VM}{Virtuelle Maschine}
 \acro{I2C}[I²C]{Inter-Integrated Circuit}
\end{acronym}

\onecolumn
%---------------------------------------------------------
% Here starts the real work
%---------------------------------------------------------

\chapter{Introduction}
 Driver attention monitoring in real time is a crucial task of advanced driver assistance systems. The driver drowsiness and distraction from the road increases the risk of accident significantly \cite{noauthor_impact_nodate} \cite{liang_how_2012}. The use of in-vehicle information systems (IVISs) such as cell phones, GPS navigation systems, and satellite radios further adds to the risk. \cite{strayer_cell_2003} \cite{lee_speech-based_2001}Hence it is necessary to design driver attention montoring systems. One way this could be helpful is to capture the driver distractions and alert the driver in case of dangerous situations. There has been lot of work done in developing driver attention monitoring in the context of Advanced Driver Assistance Systems(ADAS) \cite{liang_real-time_2007} However, there is no system which generalises the driver head pose estimation across various drivers, cars and perspectives. Convolutional Neural Networks (CNNs) have been successful in various image classification and object detection tasks \cite. In this project, the feasibility of CNNs in driver monitoring systems is analysed. 
 
\section{Problem statement}
 
The aim of this project is to use CNNs to classify the driver gaze zones. However training CNNs from scratch is often time consuming and difficult. It requires learning of millions of parameters and a large number of annotated images for training. Training CNNs for smaller datasets often leads to overfitting. Transfer learning solves this problem by using pre trained weights learnt by CNNs on large scale datasets. \cite In this project, two different networks trained on the ImageNet \cite dataset is fine tuned to classify driver gaze zones in the DrivFace dataset \cite. The DrivFace database  \cite contains images sequences of subjects while driving in real scenarios. It is composed of 606 samples of 640*480 pixels each, acquired over different days from 4 drivers (2 women and 2 men) with several facial features like glasses and beard. The performance of the transfer learning network on DrivFace dataset is compared against Deepgaze \cite , a CNN trained on AFLW dataset \cite .

\section{Structure of the project}
The main focus of this project work can be summarised as

\begin{enumerate}
	\item To study the application of CNNs in head pose estimation of driver inside a car and to verify the robustness of the algorithm against occlusions, illumination changes and different poses of the driver.
	\item To train and validate the CNN using the approach of transfer learning on the DrivFace \cite dataset with real time dashboard images of drivers inside a car.
	\item To compare the performance of our CNN against Deepgaze \cite , a CNN trained on AFLW dataset \cite .
	
\end{enumerate}




\chapter{Related work}
% \input{src/example_tables} % Load Data from File example_tables
\begin{center}
\begin{tabular}{| p{5cm}| p{5cm}  | l | l |}
\hline
Research study & Objective & Classifier\\
\hline
Driver Gaze Zone Estimation using Convolutional Neural Networks:
A General Framework and Ablative Analysis \cite{} & Gaze zone estimation
using head pose dynamics & Random Forest\\
\hline
On Driver Gaze Estimation: Explorations and Fusion of Geometric and
Data Driven Approaches \cite{} & Gaze zone estimation using fusion of geometric and learning based  method & SVM\\ 
\hline
Driver Gaze Region Estimation Without Using Eye Movement \cite{} & Gaze zone estimation
using spatial configurations of facial landmarks & Random Forest\\
\hline
Head pose estimation in the wild using Convolutional Neural Networks and adaptive gradient methods \cite{} & Head pose estimation as yaw, pitch and roll angles & CNN\\
\hline
\end{tabular}
\captionof{table}{Related research work on driver head pose estimation}
\label{tab:table1}
\end{center}

\chapter{Background}
 In this chapter we discuss the theoretical concepts of neural networks, computer vision and deep learning required for understanding the implementation of the project. First, the details of artificial intelligence, machine learning and deep learning are discussed. Finally, the application of deep learning to computer vision is examined in detail. 
 
 \section{Machine learning}
 
Machine learning is used to solve a wide variety of problems in computer vision, speech processing, statistics etc,. It is a subset of artificial intelligence where the computer is shown data to learn patterns and solve the given problem without being explicitly programmed to do so \cite. Computers have been successful in several tasks that were considered impossible by humans. However they fail to do simple tasks such as recognising objects or speech. Hence, machine learning algorithms were designed to infer the result from features of the input. In most of the cases these features needed to be hand-crafted by an expert. The algorithms work better when given better features. As the availability of data and the computational power has increased in the recent years, machine learning has become more and more practical and successful in various application domains.

\subsection{Types}
Machine learning algorithms can be broadly classified into supervised learning, unsupervised learning and reinforcement learning. In \textit{supervised learning} the algorithm is trained using labelled training data and then shown with test data to predict the results. For example, in object detection problems a training data set with annotated images is shown to the model through which the model learns the representations and the mapping from input to output. After training the model is able to predict the labels of unseen images. Supervised learning can be further classified into classification and regression. In \textit{classification}, the algorithm tries to predict the discrete output class the input belongs to, whereas in \textit{regression} the output is a continuous value. \textit{Unsupervised learning} is the process of building the model without the help of labelled data. It can also be considered as a problem of clustering a given dataset \cite. The machine learning algorithm needs to separate the set of data points into groups in the best way possible. \textit{Reinforcement learning} uses a system of rewards and punishments. The algorithm learns by interacting with its environment. The algorithm receives rewards for performing correctly and penalties for performing incorrectly. The algorithm learns without the intervention of human by maximising the rewards and minimising the penalties. 

\subsection{Features}

Features are the attributes in the data which are most relevant to the machine learning problem. Selection of features which enhance the performance of the model is a crucial step in machine learning. Feature selection methods are used to remove redundant and irrelevant attributes from data that either do not contribute to the accuracy of the model or may even decrease the accuracy of the model. There are different feature selection techniques such as 

\section{The perceptron}
An artificial neuron or perceptron is modelled similar to the neurons in the human brain. It takes several inputs and performs a weighted summation to produce an output. The weight of the perceptron is determined during the training stage. The training is performed using a method called \textit{gradient descent} which will be explained in later sections.  

\begin{figure}[h]
\centering
\includegraphics[width=0.6\textwidth]{image3.png}
\caption{The perceptron}
\label{fig:pic3}
\end{figure}

 The weighted sum is passed through a non-linear function called \textit{activation function} to capture the non-linearities in the input.  An \textit{activation function} decides whether a neuron should fire or not. There are various activation functions as shown in \ref{fig:act}. Sigmoid is useful for converting any value to probabilities and can be used for binary classification. The tanh maps input to a value in the range of -1 to 1 and are more stable than sigmoid. The ReLU maps input x to max (0, x) and works well for a large range of problems.
 
\begin{figure}[h]
    \subfigure[Sigmoid function]{\includegraphics[width=0.30\textwidth]{image4} \label{fig:pic4}}
    \subfigure[Tanh function]{\includegraphics[width=0.30\textwidth]{image5}\label{fig:pic5}}
    \subfigure[RELU function]{\includegraphics[width=0.30\textwidth]{image6}\label{fig:pic6}}
\caption{Some common activation functions}
\label{fig:act}
\end{figure}


 

\section{Artificial Neural Networks}

Artificial neural network is a collection of perceptrons and activation functions. The perceptrons are connected to each other to form the hidden layers as shown in \ref{fig:pic7}. The training process determines the values of these weights and biases. The training is started by initialising the weights and biases to random values. The error is computed by taking the difference of the actual output to the ground truth. Based on the loss, the weights and biases are tuned in steps. The training is stopped when the error can be minimised anymore and during this point the model is said to learn the features in the input.


\begin{figure}[h]
\centering
\includegraphics[width=0.6\textwidth]{image7.png}
\caption{Artificial Neural Network}
\label{fig:pic7}
\end{figure}


\section{Training the neural network}

\subsection{Backpropagation}

One of the commonly used algorithm for training the neural networks is the backpropagation algorithm. The weights are updated from the back based on the error that is calculated. The weights are updated using the gradient descent algorithm which is explained in the following section.

\subsection{Gradient Descent}

Often in machine learning, finding the best model for a certain situation means to minimise the error of the model or maximise the likelihood of the data. Hence it can be seen as finding the solution for an optimisation problem. Gradient descent is one of the optimisation problems which is widely used in the algorithms of machine learning and deep learning. 

\subsubsection{Idea}

Suppose we have some function \textbf{f(x)} that takes as input a vector of real numbers and outputs a single real number. One such simple function is given in equation \ref{gradient}. 

\begin{equation} \label{gradient}
f(x) = x^2  \in R
\end{equation}

The \textit{gradient} of \textbf{f(x)} gives the input direction in which the function \textbf{f(x)} most quickly increases. One approach to maximising a function is to pick a random starting point, compute the gradient, take a small step in the direction of the gradient, and repeat with the new starting point. Similarly, we can try to minimise a function by taking small steps in the opposite direction, as shown in \ref{fig:pic0}. 

\begin{figure}[h]
\centering
\includegraphics[width=0.6\textwidth]{image1.png}
\caption{Finding a minimum using gradient descent}
\label{fig:pic0}
\end{figure}

This procedure will work very well if the function has a unique global minimum. If a function has multiple (local) minima, this procedure might find the wrong one of them, in which case we might re-run the procedure from a variety of starting points. If a function has no minimum, then it is possible the procedure might go on forever.

\subsubsection{Estimating the gradient}


If f is a function of one variable, its derivative at a point x measures how f(x) changes when we make a very small change to x. The derivative is the slope of the tangent line at (x, f(x)). The gradient can be estimated as given in \ref{eqn:2} by considering h to be very small.

\begin{equation} \label{eqn:2}
Gradient = \frac{f(x+h) - f(x)}{h}
\end{equation}

If f is a function of multiple variables then it has multiple partial derivatives each indicating the change in f when we make small changes to one of the input variables by holding the other variables constant. The learning rate $\eta$ determines the size of the steps we take to reach a (local) minimum. There are three variants of gradient descent as explained in the following sections.

\section{Types of gradient descents }

\subsection{Batch gradient descent}

Batch gradient descent or vanilla gradient descent calculates the gradient of the cost function w.r.t the parameters $\theta$ for the entire training dataset. 

\begin{equation} \label{eqn:3}
\theta = \theta - \eta \cdot \Delta_{\theta} J(\theta)
\end{equation}

Batch gradient descent is slow since we need to calculate the gradients for the whole dataset to make just one update of the parameters. Batch gradient descent is guaranteed to converge to the global minimum for convex error surfaces and to a local minimum for non-convex surfaces.

\subsection{Stochastic gradient descent}

Stochastic gradient descent (SGD) performs parameter update for each training sample. Batch gradient descent performs redundant computations for large gradients since it recomputes the gradients for similar examples before each update. SGD does not have this problem since it performs one update for each training data and is much faster. These frequent updates cause the objective function to fluctuate which may lead to overshooting. However, by setting the optimal learning rate, SGD can show same behaviour as the batch gradient descent.

\begin{equation} \label{eqn:4}
\theta = \theta - \eta \cdot \Delta_{\theta} J(\theta; x^{(i)}; y^{(i)})
\end{equation}


\subsection{Mini-batch gradient descent}

Mini-batch gradient descent takes the best of SGD and batch gradient descent. It updates the parameters for every mini-batch of \textit{n} training samples. It reduces the variance of the parameter updates and hence more stable convergence. It also makes computations more efficient. 

\begin{equation} \label{eqn:5}
\theta = \theta - \eta \cdot \Delta_{\theta} J(\theta; x^{(i:i+n)}; y^{(i:i+n)})
\end{equation}


\subsubsection{Challenges of mini-batch gradient descent}

\begin{itemize}
	\item Finding the optimum learning rate is difficult. A learning rate which is too small will take lots of time to converge and a learning rate too fast might overshoot and oscillate around the minimum.
	\item Neural networks usually have highly non-convex error functions with saddle points. These are the points where one dimension slopes up and another slopes down. The SGD finds these points very hard to escape since the gradient is close to zero in all dimensions.
\end{itemize}

\chapter{Convolutional Neural Networks}

Convolutional neural networks are very similar to the perceptron. They are made up of neurons with weights and biases. Each neuron performs a product of the input with the weights and adds a non-linearity at the end. They have loss functions and a fully connected layers at the end. However, in convolutional neural networks the inputs are exclusively images which makes the forward propagation easier to implement and also reduces the number of parameters in the network.

\subsection{Architecture}

The regular neural networks do not scale to full images since they have fully connected layers at the input. For example, an image of 240*480*3 would lead to neurons that have 240*480*3 weights. This would lead to a huge number of parameters and hence to overfitting. In a convolutional neural network, the neurons in a layer will only be connected to a small region of the layer before it, instead of a fully connected network. A convNet is made up of layers and each layer transforms an input 3D volume to an output 3D volume with some differentiable function.

\subsection{Layers in convolutional neural networks}

There are three main types of layers in a convNet: Convolutional layer, Pooling layer and a Fully-Connected layer. The first layer is the input layer which holds the raw pixel values of the image.

\subsubsection{Convolution layer}






\chapter{Figures}
%\input{src/example_figures} % Load Data from File example_figures

\chapter{Referencing}
% Alternativ just write your text under \chapter like this example

\blindtext 

\blindtext \footnote{Here is an area for your Notes}

\blindtext \footnote{Seite 11}
\blindtext 
\blindtext 


\chapter{Subchapter}

\section{sub 1}
\blindtext[3]
\section{sub 2}
\blindtext[3]
\subsection{sub 2.1}
\blindtext[3]

\subsection{sub 2.2}
\blindtext[3]

%---------------------------------------------------------
% bibliography based on Springer Design
%---------------------------------------------------------

%\bibliographystyle{splncs03}
%\bibliography{/Users/adarshmallandur/Desktop/bibliography.bib}

\printindex

\end{document}
